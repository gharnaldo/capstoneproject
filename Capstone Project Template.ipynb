{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Capstone\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This Project aims to provide useful information to analysts as well as for the immigration staff in order they can make decisions regarding immigration process because they will be able to access what is the current and historical situation about population who have entered the country, what is the relation with demographics indicators and also what has been the behavior regarding COVID19 in the country where visitors resides.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_sas('I94_SAS_Labels_Descriptions.SAS')\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "dfi = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "This Project aims to provide useful information to analysts as well as for the immigration staff in order they can make decisions regarding immigration process because they will be able to access what is the current and historical situation about population who have entered the country, what is the relation with demographics indicators and also what has been the behavior regarding COVID19 in the country where visitors resides. For that we have built a Datapipeline by using pandas, spark with python. The information is taken from different sources, organize them into a model and written into parquet files.  \n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "* Immigration data comes from the <a href=\"https://www.trade.gov/national-travel-and-tourism-office\">US National Tourism and Trade Office</a>\n",
    "* US cities demographics information is provided with the project. Likewise data of countries, us states and i94ports to ensure the data quality.\n",
    "* COVID19 by country is from <a href=\"https://www.kaggle.com/datasets/jcsantiago/covid19-by-country-with-government-response\">Kaggle</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum, avg\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Parses the file I94_SAS_Labels_Descriptions.SAS dinamically by iterating each line of each group of data within the file, discard the data that shouldn't be used, and then move the data into a dictionary and then into a pandas Dataframe.\n",
    "def build_sas_table(target,array_words,keytype):\n",
    "    array_valids = {}\n",
    "    with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "        start = False\n",
    "        for line in f:\n",
    "            if not start:\n",
    "                match_start = re.compile(r'%s$' %(target)).search(line)\n",
    "            if match_start:\n",
    "                start = True\n",
    "                match_end = re.compile(r';$').search(line)\n",
    "                if match_end:\n",
    "                    break\n",
    "                if keytype == 1:\n",
    "                    match = re.compile(r\"'([^=]*)'.*'(.*)'\").search(line)\n",
    "                else:\n",
    "                    match = re.compile(r\"([^=]*).*'(.*)'\").search(line)\n",
    "                if match:         \n",
    "                    i94port_invalid = False\n",
    "                    for i in array_words:             \n",
    "                        if re.search(i,match[2]):                       \n",
    "                            i94port_invalid = True\n",
    "                            break\n",
    "                    if not i94port_invalid:\n",
    "                        array_valids[match[1]]=match[2].strip()\n",
    "    return array_valids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract the data from I94_SAS_Labels_Descriptions.SAS to clean it and generate the Dataframe for dim_i94ports\n",
    "dfi94port = pd.DataFrame.from_dict(build_sas_table(\"i94prtl\",['No PORT','Collapsed'],1), orient='index', columns = {'i94port_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract the data from I94_SAS_Labels_Descriptions.SAS to clean it and generate the Dataframe for dim_countries\n",
    "country = pd.DataFrame.from_dict(build_sas_table(\"i94cntyl\",['INVALID','Collapsed','No Country'],2), orient='index', columns = {'country_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract the data from I94_SAS_Labels_Descriptions.SAS to clean it and generate the Dataframe for dim_us_states\n",
    "us_states = pd.DataFrame.from_dict(build_sas_table(\"i94addrl\",[],1), orient='index', columns = {'us_states_codes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read the file covid19_by_country.csv\n",
    "covid19_by_country = pd.read_csv('covid19_by_country.csv', sep=',')\n",
    "covid19_by_country_table = spark.createDataFrame(covid19_by_country) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read the file us-cities-demographics.csv\n",
    "demographic = pd.read_csv('us-cities-demographics.csv', sep=';')\n",
    "demographic_table = spark.createDataFrame(demographic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "<img src=\"../assets/ER_diagram.PNG\" width=\"1250\"/>\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "* Given the file I94_SAS_Labels_Descriptions.SAS is in the project's root directory, likewise the different sources (covid19_by_country.csv, us-cities-demographics.csv)\n",
    "* Parse the file I94_SAS_Labels_Descriptions.SAS dinamically by iterating each line of each group of data within the file, clean the data, and then move it into a dictionary and then into a pandas Dataframe.\n",
    "* Generate the TempView for dim_i94ports table. \n",
    "* Generate the TempView for dim_countries table.\n",
    "* Generate the TempView for dim_us_states table.\n",
    "* Read the file covid19_by_country.csv and then generate the TempView for dim_covid_by_country table, grouping the data by country and leaving the most recient number of active cases.\n",
    "* Read the file us-cities-demographics.csv and then generate the TempView for dim_demographic table, grouping the data by us_state and summing the foreignborn and total population.\n",
    "* Read the folder where the immigration data is, clean the data by joining on dim_i94ports table, dim_countries table table, dim_us_states table and dim_demographic table.\n",
    "* Generate the TemView for dim_immigration table.\n",
    "* Group the dim_immigration table by us_state and join it on dim_covid_by_country table.\n",
    "* Generate the TemView for fact_immigration table.\n",
    "* Write the parquet files for the tables: dim_i94ports, dim_countries, dim_us_states, dim_demographic, dim_covid_by_country and fact_immigration.\n",
    "* Run quality checks to ensure the data were loaded properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|index|        i94port_name|\n",
      "+-----+--------------------+\n",
      "|  ALC|           ALCAN, AK|\n",
      "|  ANC|       ANCHORAGE, AK|\n",
      "|  BAR|BAKER AAF - BAKER...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate TempView for dim_i94ports table\n",
    "dfi94port.reset_index(drop=False,inplace=True)\n",
    "i94ports_table = spark.createDataFrame(dfi94port) \n",
    "i94ports_table.createOrReplaceTempView(\"i94ports_table\")\n",
    "i94ports_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|  index|        country_name|\n",
      "+-------+--------------------+\n",
      "|   582 |MEXICO Air Sea, a...|\n",
      "|   236 |         AFGHANISTAN|\n",
      "|   101 |             ALBANIA|\n",
      "+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate TempView for dim_countries table\n",
    "country.reset_index(drop=False,inplace=True)\n",
    "countries_table = spark.createDataFrame(country) \n",
    "countries_table.createOrReplaceTempView(\"countries_table\")\n",
    "countries_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|index|us_states_codes|\n",
      "+-----+---------------+\n",
      "|   AL|        ALABAMA|\n",
      "|   AK|         ALASKA|\n",
      "|   AZ|        ARIZONA|\n",
      "+-----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate TempView for dim_us_states table\n",
    "us_states.reset_index(drop=False,inplace=True)\n",
    "us_states_table = spark.createDataFrame(us_states) \n",
    "us_states_table.createOrReplaceTempView(\"us_states_table\")\n",
    "us_states_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#*****DIM COVID19 TABLE*****\n",
    "#Generate TempView for dim_covid_by_country table grouped by country\n",
    "covid19_table_grouped = covid19_by_country_table.select(\"Country\",\"confirmed_inc\",\"Date\") \\\n",
    "                    .groupBy(col(\"Country\").alias(\"country\")) \\\n",
    "                    .agg({\"Date\":\"last\",\"confirmed_inc\":\"last\"}) \\\n",
    "                    .withColumnRenamed('last(Date)','date') \\\n",
    "                    .withColumnRenamed('last(confirmed_inc)','confirmed_inc')\n",
    "covid19_table_grouped.createOrReplaceTempView(\"covid19_table_grouped\")\n",
    "covid19_table_grouped.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+---------------+-----------+\n",
      "|statecode|        medianage|totalpopulation|foreignborn|\n",
      "+---------+-----------------+---------------+-----------+\n",
      "|       AZ|35.03750000000001|       22497710|  3411565.0|\n",
      "|       SC|33.82500000000001|        2586976|   134019.0|\n",
      "|       LA|34.62500000000001|        6502975|   417095.0|\n",
      "+---------+-----------------+---------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate TempView for dim_demographic table grouped by country\n",
    "demographic_table_grouped = demographic_table.select(\"State Code\",\"Foreign-born\",\"Total Population\",\"Median Age\") \\\n",
    "                    .groupBy(col(\"State Code\").alias(\"statecode\")) \\\n",
    "                    .agg({\"Foreign-born\":\"sum\",\"Total Population\":\"sum\",\"Median Age\":\"mean\"}) \\\n",
    "                    .withColumnRenamed('sum(Foreign-born)','foreignborn') \\\n",
    "                    .withColumnRenamed('sum(Total Population)','totalpopulation') \\\n",
    "                    .withColumnRenamed('avg(Median Age)','medianage') \n",
    "demographic_table_grouped.createOrReplaceTempView(\"demographic_table_grouped\")\n",
    "demographic_table_grouped.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generate the TempView for dim_immigration table joining on dim_countries, dim_i94ports, dim_us_states and dim_demographic \n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load('/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_immigration.createOrReplaceTempView(\"immigration_table_temp\")\n",
    "immigration_table_temp = spark.sql(\"\"\"\n",
    "    SELECT i94yr, i94mon, i94res, i94port, i94addr,\n",
    "           countries_table.country_name,\n",
    "           demographic_table_grouped.foreignborn\n",
    "    FROM immigration_table_temp\n",
    "    JOIN countries_table ON (immigration_table_temp.i94res = countries_table.index)\n",
    "    JOIN i94ports_table ON (immigration_table_temp.i94port = i94ports_table.index)\n",
    "    JOIN us_states_table ON (immigration_table_temp.i94addr = us_states_table.index)\n",
    "    LEFT JOIN demographic_table_grouped ON (immigration_table_temp.i94addr = demographic_table_grouped.statecode)\n",
    "    \"\"\")\n",
    "immigration_table_temp.show(3)\n",
    "immigration_table_temp.createOrReplaceTempView(\"immigration_table_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Join the dim_immigration table on dim_covid_by_countries the get the fact table\n",
    "immigration_table_temp = spark.sql(\"\"\"\n",
    "    SELECT i94yr, i94mon, i94res, i94port, i94addr,country_name,foreignborn,\n",
    "            covid19_table_grouped.confirmed_inc\n",
    "    FROM immigration_table_temp\n",
    "    LEFT JOIN covid19_table_grouped ON (LOWER(immigration_table_temp.country_name) LIKE '%' || LOWER(covid19_table_grouped.country) || '%')\n",
    "    \"\"\")\n",
    "immigration_table_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generate the TempView for fact_immigration table grouped by year, month and us_states\n",
    "immigration_table_temp.groupBy(\"i94yr\",\"i94mon\",\"i94addr\") \\\n",
    "                    .agg({\"foreignborn\":\"last\",\"confirmed_inc\":\"last\"}) \\\n",
    "                    .withColumnRenamed('last(foreignborn)','foreignborn') \\\n",
    "                    .withColumnRenamed('last(confirmed_inc)','confirmed_inc') \\\n",
    "                    .show()\n",
    "fact_immigration_table = immigration_table_temp.createOrReplaceTempView(\"fact_immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_i94ports into parquet file\n",
    "i94ports_table.write.parquet(\"output_data/dim_i94ports/dim_i94ports.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_countries into parquet file\n",
    "countries_table.write.parquet(\"output_data/dim_countries/dim_countries.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_us_states into parquet file\n",
    "us_states_table.write.parquet(\"output_data/dim_us_states/dim_us_states.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_covid_by_country into parquet file\n",
    "covid19_table_grouped.write.partitionBy(\"country\").parquet(output_data + \"output_data/dim_covid_by_country/dim_covid_by_country.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_demographic into parquet file\n",
    "demographic_table_grouped.write.parquet(\"output_data/dim_demographic/dim_demographic.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write dim_immigration into parquet file\n",
    "immigration_table_temp.write.partitionBy(\"i94addr\").parquet(output_data + \"output_data/dim_immigration/dim_immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write fact_immigration into parquet file\n",
    "fact_immigration_table.write.partitionBy(\"i94addr\").parquet(output_data + \"output_data/fact_immigration/fact_immigration.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records for dim_i94ports table is: 588\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "print(f\"Total records for dim_i94ports table is: \" + str(i94ports_table.count())) \n",
    "print(f\"Total records for dim_countries table is: \" + str(countries_table.count())) \n",
    "print(f\"Total records for dim_us_states table is: \" + str(us_states_table.count())) \n",
    "print(f\"Total records for dim_covid_by_country table is: \" + str(covid19_table_grouped.count())) \n",
    "print(f\"Total records for dim_demographic table is: \" + str(demographic_table_grouped.count())) \n",
    "print(f\"Total records for dim_immigration table is: \" + str(immigration_table_temp.count())) \n",
    "print(f\"Total records for fact_immigration table is: \" + str(fact_immigration_table.count())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "dim_demographic\n",
    "* statecode: US States code\n",
    "* medianage: Population average age in that US State\n",
    "* totalpopulation: Total population in that US State\n",
    "* foreignborn: Foreign born population in that specific US State\n",
    "\n",
    "dim_immigration\n",
    "* i94yr: 4 digits year\n",
    "* i94mon: Numeric month\n",
    "* i94port: Destination city\n",
    "* i94res: Country code where the immigrant resides\n",
    "* i94addr: US State\n",
    "* country_name: Country name where the immigrant resides\n",
    "* foreignborn: Foreign born population in that specific US State\n",
    "* confirmed_inc: COVID19 active cases at the year and month in the country where the immigrant resides\n",
    "\n",
    "dim_i94ports\n",
    "* index: Destination city code\n",
    "* i94port: Destination city name\n",
    "\n",
    "dim_countries\n",
    "* index: Country code\n",
    "* country_name: Country name\n",
    "\n",
    "dim_us_states\n",
    "* index: US State code\n",
    "* country_name: US State name\n",
    "\n",
    "dim_covid19_by_country\n",
    "* country: Country name\n",
    "* date: Date of statistics\n",
    "* confirmed_inc: Confirmed cases\n",
    "\n",
    "fact_immigration\n",
    "* i94yr: 4 digits year\n",
    "* i94mon: Numeric month\n",
    "* i94addr: US State\n",
    "* foreignborn: Foreign born population in that specific US State\n",
    "* confirmed_inc: COVID19 active cases at the year and month in the country where the immigrant resides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Data should be updated daily because immigration process occurs at any time as well as COVID19 active cases. Demographic information could by updated yearly.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * If the data was increased by 100x is recommendable to move the Pipeline to a AWS EMR.\n",
    " * If the data populates a dashboard that must be updated on a daily basis by 7am every day is recommendable to set up Airflow Schedule and implement the same code in Operators to do that in the correct fashion.\n",
    " * If the database needed to be accessed by 100+ people is recommendable to populate a AWS Redshift with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
